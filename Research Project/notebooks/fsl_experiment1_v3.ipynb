{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwells52/creating-ai-enabled-systems/blob/main/Research%20Project/notebooks/fsl_experiment1_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBD68iPadsti"
      },
      "source": [
        "### Install EasyFSL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWg5yaDZRPAS",
        "outputId": "141ceb4c-c76f-4143-912a-dfc6c68629e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting easyfsl\n",
            "  Downloading easyfsl-1.4.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from easyfsl) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from easyfsl) (1.5.3)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from easyfsl) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from easyfsl) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from easyfsl) (4.65.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->easyfsl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->easyfsl) (2022.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->easyfsl) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->easyfsl) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->easyfsl) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->easyfsl) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->easyfsl) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->easyfsl) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->easyfsl) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->easyfsl) (16.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.7.0->easyfsl) (2.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->easyfsl) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->easyfsl) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.7.0->easyfsl) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.7.0->easyfsl) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.7.0->easyfsl) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.7.0->easyfsl) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->easyfsl) (1.3.0)\n",
            "Installing collected packages: easyfsl\n",
            "Successfully installed easyfsl-1.4.0\n"
          ]
        }
      ],
      "source": [
        "%pip install easyfsl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EIjDfwjdwoT"
      },
      "source": [
        "### Download Humpback Whale Identification dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpFPp8FTD2KY",
        "outputId": "7e1ab1da-d539-4582-ab5e-a3804fd05c34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaIJSEeFdNK5",
        "outputId": "2309d0ca-22a7-4e02-c0de-5ab85e7e4349",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading humpback-whale-identification.zip to /content\n",
            "100% 5.50G/5.51G [04:49<00:00, 17.1MB/s]\n",
            "100% 5.51G/5.51G [04:49<00:00, 20.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "!rm -rf /root/.kaggle && mkdir /root/.kaggle && cp /content/drive/MyDrive/Research-Project/kaggle.json /root/.kaggle/kaggle.json && chmod 600 /root/.kaggle/kaggle.json && kaggle competitions download -c humpback-whale-identification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!unzip humpback-whale-identification.zip"
      ],
      "metadata": {
        "id": "EAA7yP2NWQNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clone GitHub repo"
      ],
      "metadata": {
        "id": "dtM6ET0hOW5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if os.path.exists('/content/creating-ai-enabled-systems/Research Project') == False:\n",
        "  !git clone https://github.com/jwells52/creating-ai-enabled-systems.git\n",
        "\n",
        "%cd creating-ai-enabled-systems/Research\\ Project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ktmxn-nPOZlR",
        "outputId": "d217885e-d515-46e8-c73c-aa3bcdcde6e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/creating-ai-enabled-systems/Research Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_HapNgJd1lq"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "U2cTdMEld26V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import json\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from easyfsl.methods import FewShotClassifier, RelationNetworks, MatchingNetworks, PrototypicalNetworks, SimpleShot, TransductiveFinetuning\n",
        "from easyfsl.utils import evaluate\n",
        "from easyfsl.samplers import TaskSampler\n",
        "\n",
        "from torch import Tensor, nn\n",
        "from torch.optim import SGD, Optimizer, Adam\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet18, resnet34, resnet152\n",
        "\n",
        "from typing import Callable\n",
        "\n",
        "from modules.data_utils import HumpbackWhaleDataset, remove_new_whale_class, create_loader\n",
        "from modules.train import train_fsl, device, transform\n",
        "from modules.plotting import fsl_plots\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBnJZl4dt0co"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uF_KyfDueIw"
      },
      "outputs": [],
      "source": [
        "train_df = remove_new_whale_class(\n",
        "  pd.read_csv('/content/creating-ai-enabled-systems/Research Project/data/training_10samples.csv')\n",
        ")\n",
        "\n",
        "test_df = remove_new_whale_class(\n",
        "  pd.read_csv('/content/creating-ai-enabled-systems/Research Project/data/validation_10samples.csv')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrIn13-Zh39T",
        "outputId": "837f230e-95ca-4867-ad78-b8494481474f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min # of samples for a class in data set = 11\n",
            "Max # of samples for a class in data set = 73\n",
            "# of classes in data set = 181\n"
          ]
        }
      ],
      "source": [
        "print(f\"Min # of samples for a class in data set = {train_df['class_count'].min()}\")\n",
        "print(f\"Max # of samples for a class in data set = {train_df['class_count'].max()}\")\n",
        "print(f\"# of classes in data set = {len(train_df['Id'].unique())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Min # of samples for a class in data set = {test_df['class_count'].min()}\")\n",
        "print(f\"Max # of samples for a class in data set = {test_df['class_count'].max()}\")\n",
        "print(f\"# of classes in data set = {len(test_df['Id'].unique())}\")\n"
      ],
      "metadata": {
        "id": "rFTerSUWpXqV",
        "outputId": "64bd8611-9803-4440-fe29-51f7e164a8d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min # of samples for a class in data set = 11\n",
            "Max # of samples for a class in data set = 48\n",
            "# of classes in data set = 46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = HumpbackWhaleDataset('/content/train', train_df, transform=transform)"
      ],
      "metadata": {
        "id": "3Fj84Tx6xASW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArafAhfS2d1V"
      },
      "source": [
        "### Train network with 1, 3, and 5 shot learning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train on training set for 1-shot, 5-shot, 5-way, 20-way\n",
        "\n",
        "# The following networks are trained\n",
        "1.  Relation Networks\n",
        "2. Matching Networks\n",
        "3. Prototypical Networks w/ Euclidean Distance\n",
        "4. Prototypical Networks w/ Cosine Similarity\n",
        "5. Transductive Finetuning\n"
      ],
      "metadata": {
        "id": "uNMcNst5M2bU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models.feature_extraction import create_feature_extractor\n",
        "\n",
        "class FeatureExtractor(torch.nn.Module):\n",
        "  '''\n",
        "  Class for extracting feature maps from model and return a tensor and not a dictionary.\n",
        "  '''\n",
        "  def __init__(self, model, layer_name):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "    self.layer_name = layer_name\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)[self.layer_name]"
      ],
      "metadata": {
        "id": "xrEvh1JWsN7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 10\n",
        "learning_rate = 1e-2\n",
        "\n",
        "# Number of Training Task for each epoch\n",
        "# A training task is a random sample of N shots (images) for M classes\n",
        "n_task_per_epoch = 100\n",
        "\n",
        "n_ways = [5, 20]\n",
        "n_shots = [1, 5]\n",
        "n_query = 5"
      ],
      "metadata": {
        "id": "IRDculIDQIKW"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_network(\n",
        "    network,\n",
        "    train_dataset,\n",
        "    n_ways, n_shots, n_query, n_tasks_per_epoch,\n",
        "    checkpoint_path,\n",
        "    n_workers=12,\n",
        "    feature_maps=False,\n",
        "    return_layer='layer4.1.bn2',\n",
        "    learning_rate=1e-2,\n",
        "    n_epochs=10\n",
        "  ):\n",
        "  losses = dict()\n",
        "\n",
        "  for n_way in n_ways:\n",
        "    losses[n_way] = dict()\n",
        "    for n_shot in n_shots:\n",
        "      train_loader = create_loader(train_dataset, n_way, n_shot, n_query, n_tasks_per_epoch, num_workers=n_workers)\n",
        "\n",
        "      resnet = resnet18(weights='DEFAULT')\n",
        "      resnet.fc = torch.nn.Flatten()\n",
        "\n",
        "      if feature_maps:\n",
        "        resnet_extractor = create_feature_extractor(resnet, return_nodes=[return_layer])\n",
        "        feature_extractor = FeatureExtractor(resnet_extractor, return_layer).to(device)\n",
        "        fsl_network = network(feature_extractor, feature_dimension=512).to(device)\n",
        "\n",
        "      else:\n",
        "        feature_extractor = resnet\n",
        "        fsl_network = network(feature_extractor).to(device)\n",
        "\n",
        "      loss_fn = torch.nn.CrossEntropyLoss()\n",
        "      optimizer = Adam(fsl_network.parameters(), lr=learning_rate)\n",
        "      # optimizer = SGD(fsl_network.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
        "      print(f'Training network under {n_way}-way {n_shot}-shot')\n",
        "      train_losses, _ = train_fsl(\n",
        "        relation_network,\n",
        "        train_loader, None,\n",
        "        optimizer, loss_fn, n_epochs=n_epochs,\n",
        "        save_model=True, save_path=f'{checkpoint_path}_{n_way}-way_{n_shot}-shot'\n",
        "      )\n",
        "\n",
        "      losses[n_way][n_way] = train_losses"
      ],
      "metadata": {
        "id": "VnsHNT8Z-0Tj"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Relation Network"
      ],
      "metadata": {
        "id": "qpGzR4OXW7He"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training Relation Network')\n",
        "rn_losses = train_network(\n",
        "    RelationNetworks,\n",
        "    train_dataset,\n",
        "    n_ways, n_shots, n_query, n_task_per_epoch,\n",
        "    '/content/drive/MyDrive/Research-Project/relation_network',\n",
        "    feature_maps=True\n",
        ")"
      ],
      "metadata": {
        "id": "TiMkDUS5DiPO",
        "outputId": "078371dc-212b-4c4f-81e6-f7f9ae328407",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Relation Network\n",
            "Training network under 5-way 1-shot\n",
            "\n",
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 100/100 [00:10<00:00,  9.78it/s, loss=1.14]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|██████████| 100/100 [00:10<00:00,  9.97it/s, loss=1.17]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|██████████| 100/100 [00:09<00:00, 10.21it/s, loss=1.17]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|██████████| 100/100 [00:09<00:00, 10.25it/s, loss=1.18]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|██████████| 100/100 [00:09<00:00, 10.11it/s, loss=1.18]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|██████████| 100/100 [00:09<00:00, 10.05it/s, loss=1.19]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|██████████| 100/100 [00:10<00:00,  9.93it/s, loss=1.18]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|██████████| 100/100 [00:09<00:00, 10.06it/s, loss=1.17]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|██████████| 100/100 [00:09<00:00, 10.01it/s, loss=1.18]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|██████████| 100/100 [00:09<00:00, 10.30it/s, loss=1.18]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving state of model checkpoint at last epoch to /content/drive/MyDrive/Research-Project/relation_network_5-way_1-shot_last_epoch\n",
            "Training network under 5-way 5-shot\n",
            "\n",
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 100/100 [00:13<00:00,  7.16it/s, loss=0.99]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|██████████| 100/100 [00:13<00:00,  7.20it/s, loss=0.994]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|██████████| 100/100 [00:14<00:00,  6.94it/s, loss=1]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|██████████| 100/100 [00:14<00:00,  7.07it/s, loss=1]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|██████████| 100/100 [00:14<00:00,  7.12it/s, loss=1]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|██████████| 100/100 [00:14<00:00,  7.09it/s, loss=1.01]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|██████████| 100/100 [00:14<00:00,  7.14it/s, loss=0.985]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|██████████| 100/100 [00:14<00:00,  7.10it/s, loss=0.99]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|██████████| 100/100 [00:14<00:00,  6.94it/s, loss=1]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|██████████| 100/100 [00:14<00:00,  7.08it/s, loss=1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving state of model checkpoint at last epoch to /content/drive/MyDrive/Research-Project/relation_network_5-way_5-shot_last_epoch\n",
            "Training network under 20-way 1-shot\n",
            "\n",
            "Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 100/100 [00:37<00:00,  2.67it/s, loss=2.33]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  94%|█████████▍| 94/100 [00:36<00:01,  4.22it/s, loss=2.32]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matching Network"
      ],
      "metadata": {
        "id": "dR6XED4CW4kK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training Matching Network')\n",
        "mn_losses = train_network(\n",
        "    MatchingNetworks,\n",
        "    train_dataset,\n",
        "    n_ways, n_shots, n_query, n_task_per_epoch,\n",
        "    '/content/drive/MyDrive/Research-Project/matching_network',\n",
        "    feature_maps=True\n",
        ")"
      ],
      "metadata": {
        "id": "wpOdS44Esj2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prototypical Network with Euclidean Distance"
      ],
      "metadata": {
        "id": "dhjYKr0WWzEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training Prototypical Network')\n",
        "pt_losses = train_network(\n",
        "    PrototypicalNetworks,\n",
        "    train_dataset,\n",
        "    n_ways, n_shots, n_query, n_task_per_epoch,\n",
        "    '/content/drive/MyDrive/Research-Project/prototypical_network',\n",
        "    feature_maps=False\n",
        ")"
      ],
      "metadata": {
        "id": "E9-dGHz2I06D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prototypical Network with Cosine Similarity"
      ],
      "metadata": {
        "id": "ZrGiEK_qWquH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training Simple Shot Network')\n",
        "ss_losses = train_network(\n",
        "    SimpleShot,\n",
        "    train_dataset,\n",
        "    n_ways, n_shots, n_query, n_task_per_epoch,\n",
        "    '/content/drive/MyDrive/Research-Project/simple_shot_network',\n",
        "    feature_maps=False\n",
        ")"
      ],
      "metadata": {
        "id": "S8cCA22pK-Fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transductive Finetuning -- In Work"
      ],
      "metadata": {
        "id": "pO3dJvuQWnai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transductive Finetuning\n",
        "\n",
        "# Train the model with classical training\n",
        "train_loader_classical = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    num_workers=12,\n",
        "    pin_memory=True,\n",
        "    shuffle=True,\n",
        ")"
      ],
      "metadata": {
        "id": "9na6KlVINGwU"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from easyfsl.modules import resnet18\n",
        "\n",
        "resnet = resnet18(weights='DEFAULT')\n",
        "resnet.fc = torch.nn.Linear(in_features=512, out_features=len(set(train_dataset.get_labels())))\n",
        "\n",
        "# model = resnet18(\n",
        "#     use_fc=True,\n",
        "#     num_classes=len(set(train_dataset.get_labels())),\n",
        "# )"
      ],
      "metadata": {
        "id": "acD-gQM4Rdqd"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_epoch_classical(model_: nn.Module, data_loader: DataLoader, optimizer: Optimizer, loss_fn: Callable, device='cuda'):\n",
        "    all_loss = []\n",
        "    model_.train()\n",
        "    with tqdm(data_loader, total=len(data_loader), desc=\"Training\") as tqdm_train:\n",
        "        for images, labels in tqdm_train:\n",
        "            print(images.shape)\n",
        "            print(labels.shape)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss = loss_fn(model_(images.to(device)), labels.to(device))\n",
        "            print(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            all_loss.append(loss.item())\n",
        "\n",
        "            tqdm_train.set_postfix(loss=mean(all_loss))\n",
        "\n",
        "    return mean(all_loss)"
      ],
      "metadata": {
        "id": "X9l9nSUJUXVT"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_network = TransductiveFinetuning(resnet).to(device)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = SGD(tf_network.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)"
      ],
      "metadata": {
        "id": "DbWzfupOSLIe"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_epochs):\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    average_loss = training_epoch_classical(\n",
        "        tf_network,\n",
        "        train_loader_classical,\n",
        "        optimizer,\n",
        "        loss_fn\n",
        "    )\n",
        "    # optimizer.step()"
      ],
      "metadata": {
        "id": "UmkQpd2MTLCl",
        "outputId": "d2f2adab-6446-4ad7-e933-4c48bc27406d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/112 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 3, 256, 512])\n",
            "torch.Size([32])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/112 [00:02<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-d547bcf7e443>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     average_loss = training_epoch_classical(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mtf_network\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtrain_loader_classical\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-acf298ce69dc>\u001b[0m in \u001b[0;36mtraining_epoch_classical\u001b[0;34m(model_, data_loader, optimizer, loss_fn, device)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easyfsl/methods/transductive_finetuning.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query_images)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 support_cross_entropy = nn.functional.cross_entropy(\n\u001b[1;32m     69\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                     \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_distance_to_prototypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/easyfsl/methods/few_shot_classifier.py\u001b[0m in \u001b[0;36ml2_distance_to_prototypes\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \"\"\"\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprototypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcosine_distance_to_prototypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mcdist\u001b[0;34m(x1, x2, p, compute_mode)\u001b[0m\n\u001b[1;32m   1220\u001b[0m             cdist, (x1, x2), x1, x2, p=p, compute_mode=compute_mode)\n\u001b[1;32m   1221\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'use_mm_for_euclid_dist_if_necessary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcompute_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'use_mm_for_euclid_dist'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cdist only supports at least 2D tensors, X1 got: 1D"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "skj0e7EaU5E9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "WBD68iPadsti",
        "4EIjDfwjdwoT"
      ],
      "gpuType": "A100",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}